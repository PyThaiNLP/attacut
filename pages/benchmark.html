
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Benchmarking &#8212; AttaCut  documentation</title>
    <link rel="stylesheet" href="../_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Reproduction" href="training.html" />
    <link rel="prev" title="Word Tokenization for Thai" href="survey.html" />
   
  <link rel="stylesheet" href="../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="benchmarking">
<span id="sec-benchmark"></span><h1>Benchmarking<a class="headerlink" href="#benchmarking" title="Permalink to this headline">¶</a></h1>
<p>We value reproducibility. Our experiments should be reproducible and expected
to have similar results when one tries. Therefore, we 1) desrcibe our
benchmarking procedure as complete as possible and 2) publish all the code with
fair amount of documentation.</p>
<p>If there is any doubt or unclear part,
please let us know. We are happy to clarify and improve the document.</p>
<p>Please note here that AttaCut models are denoted as <strong>AttaCut-SC</strong> and
<strong>AttaCut-C</strong>. The former is AttaCut with syllable and character features,
while the latter uses only character feature.</p>
<div class="section" id="tokenization-quality">
<h2>Tokenization Quality<a class="headerlink" href="#tokenization-quality" title="Permalink to this headline">¶</a></h2>
<p>Tokenization quality is measured in terms of <strong>precision</strong>, <strong>recall</strong>, and
<strong>f1</strong>. We do the measurements in two levels, namely character and word.
Figure below describes how these metrics are computed:</p>
<div class="figure align-default" id="id4">
<img alt="../_images/evaluation-long.png" src="../_images/evaluation-long.png" />
<p class="caption"><span class="caption-text">Character- and Word-Level Metrics for Word Tokenization</span><a class="headerlink" href="#id4" title="Permalink to this image">¶</a></p>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Character</span><span class="o">-</span><span class="n">Level</span><span class="p">:</span>
<span class="p">[</span><span class="n">P</span><span class="p">]</span><span class="n">recision</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span> <span class="n">TP</span> <span class="o">+</span> <span class="n">FP</span> <span class="p">)</span>
<span class="p">[</span><span class="n">R</span><span class="p">]</span><span class="n">ecall</span> <span class="o">=</span> <span class="n">TP</span> <span class="o">/</span> <span class="p">(</span> <span class="n">TP</span> <span class="o">+</span> <span class="n">FN</span> <span class="p">)</span>
<span class="n">f1</span> <span class="o">=</span> <span class="mi">2</span><span class="n">PR</span> <span class="o">/</span> <span class="p">(</span><span class="n">P</span><span class="o">+</span><span class="n">R</span><span class="p">)</span>

<span class="n">Word</span><span class="o">-</span><span class="n">Level</span><span class="p">:</span>
<span class="n">P</span> <span class="o">=</span> <span class="c1">#✓ / #◼︎ in prediction</span>
<span class="n">R</span> <span class="o">=</span> <span class="c1">#✓ / #◼︎ in text</span>
</pre></div>
</div>
<p>To increase reproducibility and ease further research, we have developed an
evaluation framework for this process. The framework contains two main
ingredients:</p>
<ol class="arabic">
<li><div class="line-block">
<div class="line"><strong>Bechmark CLI</strong></div>
<div class="line">At the moment, this CLI can be found at <a class="reference external" href="https://github.com/PyThaiNLP/tokenization-benchmark">&#64;pythainlp’s tokenization-benchmark</a>, but it will be soon released in the main PyThaiNLP package (version 2.1). Please see it this milestone <a class="footnote-reference brackets" href="#milestone" id="id1">1</a> for recent updates.</div>
</div>
</li>
<li><div class="line-block">
<div class="line"><strong>Result Visualization and Comparison Website</strong></div>
<div class="line">This website serves as a tool for error analysis on tokenization results as well as a benchmark collection of other publicly available tokenizers.</div>
</div>
<blockquote>
<div><div class="figure align-default" id="id5">
<img alt="https://camo.githubusercontent.com/85984f46bb0db3e2bb86b16969b570b7faf4535a/68747470733a2f2f692e696d6775722e636f6d2f56564159485a4d2e706e67" src="https://camo.githubusercontent.com/85984f46bb0db3e2bb86b16969b570b7faf4535a/68747470733a2f2f692e696d6775722e636f6d2f56564159485a4d2e706e67" />
<p class="caption"><span class="caption-text">Tokenization Benchmark Visualization <a class="footnote-reference brackets" href="#viz" id="id2">2</a></span><a class="headerlink" href="#id5" title="Permalink to this image">¶</a></p>
</div>
</div></blockquote>
</li>
</ol>
<div class="section" id="results">
<h3>Results<a class="headerlink" href="#results" title="Permalink to this headline">¶</a></h3>
<p>…</p>
</div>
</div>
<div class="section" id="speed">
<h2>Speed<a class="headerlink" href="#speed" title="Permalink to this headline">¶</a></h2>
<p>Our speed benchmarking is done on standardized environments, namely Google Colab
and AWS’s EC2 instances (t2.small &amp; t2.medium).</p>
<div class="section" id="benchmarking-on-google-colab">
<h3>Benchmarking on Google Colab<a class="headerlink" href="#benchmarking-on-google-colab" title="Permalink to this headline">¶</a></h3>
<p>Due to Google Colab’s accessibilty and convenience, we use Google Colab for our
early speed benchmarking. In this experiment, we vary the length of input text
and measure the speed of tokenizers.</p>
<div class="figure align-default" id="id6">
<img alt="../_images/colab-speed-benchmark.png" src="../_images/colab-speed-benchmark.png" />
<p class="caption"><span class="caption-text">Tokenization Time of PyThaiNLP’s newmm, DeepCut, and AttaCut on Google Colab</span><a class="headerlink" href="#id6" title="Permalink to this image">¶</a></p>
</div>
<p>From the figure above, we can see that our AttaCut models are significantly
faster than DeepCut.</p>
</div>
<div class="section" id="benchmarking-on-ec2-instances">
<h3>Benchmarking on EC2 Instances<a class="headerlink" href="#benchmarking-on-ec2-instances" title="Permalink to this headline">¶</a></h3>
<p>Practically, tokenization is part of NLP pipelines that is usually done on
cloud instances, such as AWS EC2, due to scalibility and cost efficiency.
Typically, these instances contain a couple of CPU cores and memory,
posing another challenge to services, i.e. tokenization, executued there.</p>
<p>Evaluating tokenizer’s speed on such an instance allows us to get realistic
results and yet reproducible. We use the training set of Wisesight Sentiment
Corpus <a class="footnote-reference brackets" href="#wisesight" id="id3">3</a> as a input dataset. The corpus contains texts from social
media and online forum platforms. The training set has around 24,000 lines and
about 1.5M characters.</p>
<div class="figure align-default" id="id7">
<img alt="../_images/speed-benchmark-ec2.png" src="../_images/speed-benchmark-ec2.png" />
<p class="caption"><span class="caption-text">Wisesight’s Training Set Tokenization Time of PyThaiNLP’s newmm, DeepCut, and AttaCut on AWS Instances.</span><a class="headerlink" href="#id7" title="Permalink to this image">¶</a></p>
</div>
<p>From the figure above, AttaCut models are fasters than other existing ML-based
tokenizers. More precisely, <strong>AttaCut-SC</strong> (our best model) is aroud <strong>6x</strong>
faster than <strong>DeepCut</strong>, the current state of the art word tokenizer for Thai,
while having a similar level of tokenization quality.</p>
<dl class="footnote brackets">
<dt class="label" id="milestone"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p><a class="reference external" href="https://github.com/PyThaiNLP/pythainlp/milestone/11">PyThaiNLP 2.1 Milestone</a></p>
</dd>
<dt class="label" id="viz"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p><a class="reference external" href="https://pythainlp.github.io/tokenization-benchmark-visualization/">Tokenization Benchmark Visualization</a></p>
</dd>
<dt class="label" id="wisesight"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p><a class="reference external" href="https://github.com/PyThaiNLP/wisesight-sentiment">PyThaiNLP. Wisesight-Sentiment Corpus, 2019</a></p>
</dd>
</dl>
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<p class="logo">
  <a href="../index.html">
    <img class="logo" src="../_static/logo.png" alt="Logo"/>
    
  </a>
</p>








<h3>Navigation</h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="survey.html">Word Tokenization for Thai</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Benchmarking</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#tokenization-quality">Tokenization Quality</a></li>
<li class="toctree-l2"><a class="reference internal" href="#speed">Speed</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="training.html">Reproduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="acknowledgement.html">Acknowledgement</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="survey.html" title="previous chapter">Word Tokenization for Thai</a></li>
      <li>Next: <a href="training.html" title="next chapter">Reproduction</a></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2019, Pattarawat Chormai et al..
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 2.2.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="../_sources/pages/benchmark.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>